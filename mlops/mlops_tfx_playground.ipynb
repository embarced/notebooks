{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdfXfXK2-CiG"
   },
   "source": [
    "# Adding TFX data validation, feature engineering and model analysis\n",
    "\n",
    "***WARNING:absl:Pusher is going to push the model without validation. Consider using Evaluator or InfraValidator in your pipeline.***\n",
    "\n",
    "Parts copied from https://www.tensorflow.org/tfx/guide#tfx_standard_components: \n",
    "1. **Basics:** https://colab.research.google.com/github/tensorflow/tfx/blob/master/docs/tutorials/tfx/penguin_simple.ipynb\n",
    "  * ExampleGen is the initial input component of a pipeline that ingests and optionally splits the input dataset: https://www.tensorflow.org/tfx/guide/examplegen\n",
    "  * Trainer trains the model: https://www.tensorflow.org/tfx/guide/trainer\n",
    "  * Pusher deploys the model on a serving infrastructure: https://www.tensorflow.org/tfx/guide/pusher\n",
    "1. **Data validation:** https://colab.research.google.com/github/tensorflow/tfx/blob/master/docs/tutorials/tfx/penguin_tfdv.ipynb\n",
    "  * https://www.tensorflow.org/tfx/guide/tfdv\n",
    "  * StatisticsGen calculates statistics for the dataset: https://www.tensorflow.org/tfx/guide/statsgen\n",
    "  * SchemaGen examines the statistics and creates a data schema: https://www.tensorflow.org/tfx/guide/schemagen\n",
    "  * ExampleValidator looks for anomalies and missing values in the dataset: https://www.tensorflow.org/tfx/guide/exampleval\n",
    "1. **Feature Engineering:** https://colab.research.google.com/github/tensorflow/tfx/blob/master/docs/tutorials/tfx/penguin_tft.ipynb\n",
    "  * https://www.tensorflow.org/tfx/guide/tft\n",
    "  * Transform performs feature engineering on the dataset: https://www.tensorflow.org/tfx/guide/transform\n",
    "1. **Model Analysis:** https://colab.research.google.com/github/tensorflow/tfx/blob/master/docs/tutorials/tfx/penguin_tfma.ipynb\n",
    "  * https://www.tensorflow.org/tfx/guide/tfma\n",
    "  * Evaluator performs deep analysis of the training results and helps you validate your exported models, ensuring that they are \"good enough\" to be pushed to production: https://www.tensorflow.org/tfx/guide/evaluator\n",
    "\n",
    "https://www.tensorflow.org/tfx/tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MSzUEiEPgpuM",
    "outputId": "ee1d1c6c-54f0-4f6a-e52b-e0c7ba7898d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.6.0\n",
      "TFX version: 1.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow version: {}'.format(tf.__version__))\n",
    "from tfx import v1 as tfx\n",
    "print('TFX version: {}'.format(tfx.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "i3OoEXQtg-c_"
   },
   "outputs": [],
   "source": [
    "from absl import logging\n",
    "logging.set_verbosity(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "Hd9fZ3gOhEs1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘original_data’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir original_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir drifted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lVMIRHNShGR6",
    "outputId": "ca9b9933-648f-44ac-cfc4-4c7eb113be52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 54421  100 54421    0     0   281k      0 --:--:-- --:--:-- --:--:--  279k\n"
     ]
    }
   ],
   "source": [
    "!curl -o original_data/data.csv https://raw.githubusercontent.com/embarced/notebooks/master/mlops/insurance-customers-risk-1500.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 54500  100 54500    0     0   260k      0 --:--:-- --:--:-- --:--:--  260k\n"
     ]
    }
   ],
   "source": [
    "!curl -o drifted_data/data.csv https://raw.githubusercontent.com/embarced/notebooks/master/mlops/insurance-customers-risk-1500-shift.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tfx.proto.Output(\n",
    "             split_config=tfx.proto.SplitConfig(splits=[\n",
    "                 tfx.proto.SplitConfig.Split(name='all', hash_buckets=3),\n",
    "#                  tfx.proto.SplitConfig.Split(name='train', hash_buckets=3),\n",
    "#                  tfx.proto.SplitConfig.Split(name='eval', hash_buckets=1)\n",
    "             ]))\n",
    "\n",
    "example_gen = tfx.components.CsvExampleGen(input_base=DATA_DIR, output_config=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_schema_pipeline(pipeline_name: str,\n",
    "                            pipeline_root: str,\n",
    "                            data_root: str,\n",
    "                            metadata_path: str) -> tfx.dsl.Pipeline:\n",
    "  \"\"\"Creates a pipeline for schema generation.\"\"\"\n",
    "  # Brings data into the pipeline.\n",
    "  example_gen = tfx.components.CsvExampleGen(input_base=data_root, output_config=output)\n",
    "\n",
    "  # NEW: Computes statistics over data for visualization and schema generation.\n",
    "  statistics_gen = tfx.components.StatisticsGen(\n",
    "      examples=example_gen.outputs['examples'])\n",
    "\n",
    "  # NEW: Generates schema based on the generated statistics.\n",
    "  schema_gen = tfx.components.SchemaGen(\n",
    "      statistics=statistics_gen.outputs['statistics'], infer_feature_shape=True)\n",
    "\n",
    "  components = [\n",
    "      example_gen,\n",
    "      statistics_gen,\n",
    "      schema_gen,\n",
    "  ]\n",
    "\n",
    "  return tfx.dsl.Pipeline(\n",
    "      pipeline_name=pipeline_name,\n",
    "      pipeline_root=pipeline_root,\n",
    "      metadata_connection_config=tfx.orchestration.metadata\n",
    "      .sqlite_metadata_connection_config(metadata_path),\n",
    "      components=components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.8 interpreter.\n",
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.8 interpreter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.38 s, sys: 4.5 ms, total: 1.38 s\n",
      "Wall time: 1.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "pipeline = _create_schema_pipeline(\n",
    "      pipeline_name='insurance-schema',\n",
    "      pipeline_root='schema-pipeline',\n",
    "      data_root='original_data',\n",
    "      metadata_path='metadata.db')\n",
    "tfx.orchestration.LocalDagRunner().run(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12\r\n",
      "drwxr-xr-x 4 olli olli 4096 Oct 26 18:19 CsvExampleGen\r\n",
      "drwxr-xr-x 4 olli olli 4096 Oct 26 18:19 SchemaGen\r\n",
      "drwxr-xr-x 4 olli olli 4096 Oct 26 18:19 StatisticsGen\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l schema-pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_metadata.proto import metadata_store_pb2\n",
    "# Non-public APIs, just for showcase.\n",
    "from tfx.orchestration.portable.mlmd import execution_lib\n",
    "\n",
    "# TODO(b/171447278): Move these functions into the TFX library.\n",
    "\n",
    "def get_latest_artifacts(metadata, pipeline_name, component_id):\n",
    "  \"\"\"Output artifacts of the latest run of the component.\"\"\"\n",
    "  context = metadata.store.get_context_by_type_and_name(\n",
    "      'node', f'{pipeline_name}.{component_id}')\n",
    "  executions = metadata.store.get_executions_by_context(context.id)\n",
    "  latest_execution = max(executions,\n",
    "                         key=lambda e:e.last_update_time_since_epoch)\n",
    "  return execution_lib.get_artifacts_dict(metadata, latest_execution.id, \n",
    "                                          metadata_store_pb2.Event.OUTPUT)\n",
    "\n",
    "# Non-public APIs, just for showcase.\n",
    "from tfx.orchestration.experimental.interactive import visualizations\n",
    "\n",
    "def visualize_artifacts(artifacts):\n",
    "  \"\"\"Visualizes artifacts using standard visualization modules.\"\"\"\n",
    "  for artifact in artifacts:\n",
    "    visualization = visualizations.get_registry().get_visualization(\n",
    "        artifact.type_name)\n",
    "    if visualization:\n",
    "      visualization.display(artifact)\n",
    "\n",
    "from tfx.orchestration.experimental.interactive import standard_visualizations\n",
    "standard_visualizations.register_standard_visualizations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-public APIs, just for showcase.\n",
    "from tfx.orchestration.metadata import Metadata\n",
    "from tfx.types import standard_component_specs\n",
    "\n",
    "metadata_connection_config = tfx.orchestration.metadata.sqlite_metadata_connection_config(\"metadata.db\")\n",
    "\n",
    "with Metadata(metadata_connection_config) as metadata_handler:\n",
    "  # Find output artifacts from MLMD.\n",
    "  example_gen_output = get_latest_artifacts(metadata_handler, \"insurance-schema\", 'CsvExampleGen')\n",
    "  example_artifacts = example_gen_output[standard_component_specs.EXAMPLES_KEY]\n",
    "\n",
    "  stat_gen_output = get_latest_artifacts(metadata_handler, \"insurance-schema\", 'StatisticsGen')\n",
    "  stats_artifacts = stat_gen_output[standard_component_specs.STATISTICS_KEY]\n",
    "\n",
    "  schema_gen_output = get_latest_artifacts(metadata_handler, \"insurance-schema\", 'SchemaGen')\n",
    "  schema_artifacts = schema_gen_output[standard_component_specs.SCHEMA_KEY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'schema-pipeline/CsvExampleGen/examples/58'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_artifacts[0].uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 32\r\n",
      "-rw-r--r-- 1 olli olli 29805 Oct 27 16:12 data_tfrecord-00000-of-00001.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l {example_artifacts[0].uri}/Split-all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'schema-pipeline/SchemaGen/schema/60'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_artifacts[0].uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4\r\n",
      "-rw-r--r-- 1 olli olli 705 Oct 27 16:12 schema.pbtxt\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l {schema_artifacts[0].uri}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature {\r\n",
      "  name: \"age\"\r\n",
      "  type: FLOAT\r\n",
      "  presence {\r\n",
      "    min_fraction: 1.0\r\n",
      "    min_count: 1\r\n",
      "  }\r\n",
      "  shape {\r\n",
      "    dim {\r\n",
      "      size: 1\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "feature {\r\n",
      "  name: \"group\"\r\n",
      "  type: INT\r\n",
      "  presence {\r\n",
      "    min_fraction: 1.0\r\n",
      "    min_count: 1\r\n",
      "  }\r\n",
      "  shape {\r\n",
      "    dim {\r\n",
      "      size: 1\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "feature {\r\n",
      "  name: \"miles\"\r\n",
      "  type: FLOAT\r\n",
      "  presence {\r\n",
      "    min_fraction: 1.0\r\n",
      "    min_count: 1\r\n",
      "  }\r\n",
      "  shape {\r\n",
      "    dim {\r\n",
      "      size: 1\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "feature {\r\n",
      "  name: \"risk\"\r\n",
      "  type: FLOAT\r\n",
      "  presence {\r\n",
      "    min_fraction: 1.0\r\n",
      "    min_count: 1\r\n",
      "  }\r\n",
      "  shape {\r\n",
      "    dim {\r\n",
      "      size: 1\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "feature {\r\n",
      "  name: \"speed\"\r\n",
      "  type: FLOAT\r\n",
      "  presence {\r\n",
      "    min_fraction: 1.0\r\n",
      "    min_count: 1\r\n",
      "  }\r\n",
      "  shape {\r\n",
      "    dim {\r\n",
      "      size: 1\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "# text file\n",
    "!cat {schema_artifacts[0].uri}/schema.pbtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘schema’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version for comparison with future data\n",
    "!cp {schema_artifacts[0].uri}/schema.pbtxt schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'schema-pipeline/StatisticsGen/statistics/59'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_artifacts[0].uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4\r\n",
      "drwxr-xr-x 2 olli olli 4096 Oct 27 16:12 Split-all\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l {stats_artifacts[0].uri}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\r\n",
      "-rw-r--r-- 1 olli olli 4713 Oct 27 16:12 FeatureStats.pb\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l {stats_artifacts[0].uri}/Split-all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary file\n",
    "# !cat {stats_artifacts[0].uri}/Split-all/FeatureStats.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp {stats_artifacts[0].uri}/Split-all/FeatureStats.pb FeatureStats.pb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Valency</th>\n",
       "      <th>Domain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>'age'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'group'</th>\n",
       "      <td>INT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'miles'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'risk'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'speed'</th>\n",
       "      <td>FLOAT</td>\n",
       "      <td>required</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Type  Presence Valency Domain\n",
       "Feature name                                \n",
       "'age'         FLOAT  required          -    \n",
       "'group'       INT    required          -    \n",
       "'miles'       FLOAT  required          -    \n",
       "'risk'        FLOAT  required          -    \n",
       "'speed'       FLOAT  required          -    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_artifacts(schema_artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><b>'all' split:</b></div><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<iframe id='facets-iframe' width=\"100%\" height=\"500px\"></iframe>\n",
       "        <script>\n",
       "        facets_iframe = document.getElementById('facets-iframe');\n",
       "        facets_html = '<script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"><\\/script><link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/master/facets-dist/facets-jupyter.html\"><facets-overview proto-input=\"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\"></facets-overview>';\n",
       "        facets_iframe.srcdoc = facets_html;\n",
       "         facets_iframe.id = \"\";\n",
       "         setTimeout(() => {\n",
       "           facets_iframe.setAttribute('height', facets_iframe.contentWindow.document.body.offsetHeight + 'px')\n",
       "         }, 1500)\n",
       "         </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_artifacts(stats_artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "-2-G4zPw2oGq"
   },
   "outputs": [],
   "source": [
    "_trainer_module_file = 'trainer.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nOUodcze2qUK",
    "outputId": "a7f575f3-a2c9-49d6-e7de-19a98466bda8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting trainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {_trainer_module_file}\n",
    "\n",
    "from tensorflow.keras.layers import InputLayer, Dense, Dropout, \\\n",
    "                                    BatchNormalization, Activation,\\\n",
    "                                    Input, concatenate\n",
    "from typing import List\n",
    "from absl import logging\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "\n",
    "from tfx import v1 as tfx\n",
    "from tfx_bsl.public import tfxio\n",
    "from tensorflow_metadata.proto.v0 import schema_pb2\n",
    "\n",
    "_FEATURE_KEYS = ['age', 'speed']\n",
    "_LABEL_KEY = 'group'\n",
    "\n",
    "_TRAIN_BATCH_SIZE = 32\n",
    "_EVAL_BATCH_SIZE = 32\n",
    "\n",
    "# Since we're not generating or creating a schema, we will instead create\n",
    "# a feature spec.  Since there are a fairly small number of features this is\n",
    "# manageable for this dataset.\n",
    "_FEATURE_SPEC = {\n",
    "    **{\n",
    "        feature: tf.io.FixedLenFeature(shape=[1], dtype=tf.float32)\n",
    "           for feature in _FEATURE_KEYS\n",
    "       },\n",
    "    _LABEL_KEY: tf.io.FixedLenFeature(shape=[1], dtype=tf.int64)\n",
    "}\n",
    "\n",
    "num_features = len(_FEATURE_KEYS)\n",
    "dropout = 0.5\n",
    "\n",
    "def _input_fn(file_pattern: List[str],\n",
    "              data_accessor: tfx.components.DataAccessor,\n",
    "              schema: schema_pb2.Schema,\n",
    "              batch_size: int = 200) -> tf.data.Dataset:\n",
    "  \"\"\"Generates features and label for training.\n",
    "\n",
    "  Args:\n",
    "    file_pattern: List of paths or patterns of input tfrecord files.\n",
    "    data_accessor: DataAccessor for converting input to RecordBatch.\n",
    "    schema: schema of the input data.\n",
    "    batch_size: representing the number of consecutive elements of returned\n",
    "      dataset to combine in a single batch\n",
    "\n",
    "  Returns:\n",
    "    A dataset that contains (features, indices) tuple where features is a\n",
    "      dictionary of Tensors, and indices is a single Tensor of label indices.\n",
    "  \"\"\"\n",
    "  return data_accessor.tf_dataset_factory(\n",
    "      file_pattern,\n",
    "      tfxio.TensorFlowDatasetOptions(\n",
    "          batch_size=batch_size, label_key=_LABEL_KEY),\n",
    "      schema=schema).repeat()\n",
    "\n",
    "\n",
    "def _build_keras_model() -> tf.keras.Model:\n",
    "  \"\"\"Creates a DNN Keras model for classifying penguin data.\n",
    "\n",
    "  Returns:\n",
    "    A Keras Model.\n",
    "  \"\"\"\n",
    "\n",
    "  inputs = [keras.layers.Input(shape=(1,), name=f) for f in _FEATURE_KEYS]\n",
    "  d = keras.layers.concatenate(inputs)\n",
    "  for _ in range(2):\n",
    "    d = Dense(500)(d)\n",
    "    d = Activation('relu')(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = Dropout(dropout)(d)\n",
    "\n",
    "  outputs = Dense(name='output', units=3, activation='softmax')(d)\n",
    "\n",
    "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=keras.optimizers.Adam(),\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "  model.summary(print_fn=logging.info)\n",
    "  return model\n",
    "\n",
    "\n",
    "# TFX Trainer will call this function.\n",
    "def run_fn(fn_args: tfx.components.FnArgs):\n",
    "  \"\"\"Train the model based on given args.\n",
    "\n",
    "  Args:\n",
    "    fn_args: Holds args used to train the model as name/value pairs.\n",
    "  \"\"\"\n",
    "\n",
    "  # ++ Changed code: Reads in schema file passed to the Trainer component.\n",
    "  schema = tfx.utils.parse_pbtxt_file(fn_args.schema_path, schema_pb2.Schema())\n",
    "  # ++ End of the changed code.\n",
    "\n",
    "  train_dataset = _input_fn(\n",
    "      fn_args.train_files,\n",
    "      fn_args.data_accessor,\n",
    "      schema,\n",
    "      batch_size=_TRAIN_BATCH_SIZE)\n",
    "  eval_dataset = _input_fn(\n",
    "      fn_args.eval_files,\n",
    "      fn_args.data_accessor,\n",
    "      schema,\n",
    "      batch_size=_EVAL_BATCH_SIZE)\n",
    "\n",
    "  model = _build_keras_model()\n",
    "\n",
    "  model.fit(\n",
    "      train_dataset,\n",
    "      steps_per_epoch=fn_args.train_steps,\n",
    "      validation_data=eval_dataset,\n",
    "      validation_steps=fn_args.eval_steps)\n",
    "\n",
    "  # The result of the training should be saved in `fn_args.serving_model_dir`\n",
    "  # directory.\n",
    "  model.save(fn_args.serving_model_dir, save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "rXeTQ4ExiHf_"
   },
   "outputs": [],
   "source": [
    "# !cat trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "sqOMX7EU7-Ec"
   },
   "outputs": [],
   "source": [
    "def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,\n",
    "                     schema_path: str, module_file: str, serving_model_dir: str,\n",
    "                     metadata_path: str) -> tfx.dsl.Pipeline:\n",
    "  \"\"\"Creates a three component penguin pipeline with TFX.\"\"\"\n",
    "  # Brings data into the pipeline.\n",
    "  example_gen = tfx.components.CsvExampleGen(input_base=data_root)\n",
    "\n",
    "  # Computes statistics over data for visualization and example validation.\n",
    "  statistics_gen = tfx.components.StatisticsGen(\n",
    "      examples=example_gen.outputs['examples'])\n",
    "\n",
    "  # NEW: Import the schema.\n",
    "  schema_importer = tfx.dsl.Importer(\n",
    "      source_uri=schema_path,\n",
    "      artifact_type=tfx.types.standard_artifacts.Schema).with_id(\n",
    "          'schema_importer')\n",
    "\n",
    "  # NEW: Performs anomaly detection based on statistics and data schema.\n",
    "  example_validator = tfx.components.ExampleValidator(\n",
    "      statistics=statistics_gen.outputs['statistics'],\n",
    "      schema=schema_importer.outputs['result'])\n",
    "\n",
    "  # Uses user-provided Python function that trains a model.\n",
    "  trainer = tfx.components.Trainer(\n",
    "      module_file=module_file,\n",
    "      examples=example_gen.outputs['examples'],\n",
    "      # NEW\n",
    "      schema=schema_importer.outputs['result'],  # Pass the imported schema.\n",
    "      train_args=tfx.proto.TrainArgs(num_steps=5000),\n",
    "      eval_args=tfx.proto.EvalArgs(num_steps=15))\n",
    "\n",
    "  # Pushes the model to a filesystem destination.\n",
    "  pusher = tfx.components.Pusher(\n",
    "      model=trainer.outputs['model'],\n",
    "      push_destination=tfx.proto.PushDestination(\n",
    "          filesystem=tfx.proto.PushDestination.Filesystem(\n",
    "              base_directory=serving_model_dir)))\n",
    "\n",
    "  # Following three components will be included in the pipeline.\n",
    "  components = [\n",
    "      example_gen,\n",
    "      \n",
    "      # NEW: Following three components were added to the pipeline.\n",
    "      statistics_gen,\n",
    "      schema_importer,\n",
    "      example_validator,\n",
    "\n",
    "\n",
    "      trainer,\n",
    "      pusher,\n",
    "  ]\n",
    "\n",
    "  return tfx.dsl.Pipeline(\n",
    "      pipeline_name=pipeline_name,\n",
    "      pipeline_root=pipeline_root,\n",
    "      metadata_connection_config=tfx.orchestration.metadata\n",
    "      .sqlite_metadata_connection_config(metadata_path),\n",
    "      components=components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rjHiypa7_HJu",
    "outputId": "78f785b0-513d-4450-e189-edf54d3caf71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tfx.orchestration.pipeline.Pipeline at 0x7f342f856220>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = _create_pipeline(\n",
    "      pipeline_name='insurance-basic',\n",
    "      pipeline_root='pipeline',\n",
    "      data_root='drifted_data',\n",
    "    \n",
    "      # NEW\n",
    "      schema_path='schema',\n",
    "      \n",
    "      module_file=_trainer_module_file,\n",
    "      serving_model_dir='model',\n",
    "      metadata_path='metadata.db')\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "W1Y3xE-C_PFO",
    "outputId": "9a3a21f8-0ea2-4792-f00e-7d5250f1758e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.8 interpreter.\n",
      "WARNING:root:Make sure that locally built Python SDK docker image has Python 3.8 interpreter.\n",
      "/home/olli/anaconda3/envs/tfx/lib/python3.8/site-packages/keras/engine/functional.py:582: UserWarning: Input dict contained keys ['miles', 'risk'] which did not match any model input. They will be ignored by the model.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 15s 3ms/step - loss: 0.7190 - sparse_categorical_accuracy: 0.6818 - val_loss: 0.5670 - val_sparse_categorical_accuracy: 0.7396\n",
      "INFO:tensorflow:Assets written to: pipeline/Trainer/model/64/Format-Serving/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pipeline/Trainer/model/64/Format-Serving/assets\n",
      "WARNING:absl:Pusher is going to push the model without validation. Consider using Evaluator or InfraValidator in your pipeline.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.3 s, sys: 11.6 s, total: 36 s\n",
      "Wall time: 19.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "tfx.orchestration.LocalDagRunner().run(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "NlGPE-vIju_Q"
   },
   "outputs": [],
   "source": [
    "metadata_connection_config = tfx.orchestration.metadata.sqlite_metadata_connection_config(\n",
    "    'metadata.db')\n",
    "\n",
    "with Metadata(metadata_connection_config) as metadata_handler:\n",
    "  ev_output = get_latest_artifacts(metadata_handler, 'insurance-basic',\n",
    "                                   'ExampleValidator')\n",
    "  anomalies_artifacts = ev_output[standard_component_specs.ANOMALIES_KEY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><b>'train' split:</b></div><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olli/anaconda3/envs/tfx/lib/python3.8/site-packages/tensorflow_data_validation/utils/display_util.py:217: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('max_colwidth', -1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4 style=\"color:green;\">No anomalies found.</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>'eval' split:</b></div><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4 style=\"color:green;\">No anomalies found.</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_artifacts(anomalies_artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "5-mlops-tfx-ext.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
