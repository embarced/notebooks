{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "intro_quickstart.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/embarced/notebooks/blob/master/deep/intro_quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdfXfXK2-CiG"
      },
      "source": [
        "# ML Quickstart\n",
        "* Notebooks\n",
        "* Python\n",
        "* Using a Machine Learning Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "j5uomaug1WV-",
        "outputId": "e9a96dff-8d99-4723-d321-d36c3a3057df"
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7.0'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1ARTIEFBm36"
      },
      "source": [
        "## Introducing image recognition: MobilNet V2 trained on the ImageNet database\n",
        "\n",
        "http://image-net.org/\n",
        "\n",
        "<a href='http://image-net.org/'>\n",
        "<img src='https://djcordhose.github.io/ml-workshop/img/imagenet.png'>\n",
        "</a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dchjxUQnV_pV"
      },
      "source": [
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "mobilnetv2_model = MobileNetV2(weights='imagenet', input_shape=(224, 224, 3))\n",
        "# mobilnetv2_model.summary()\n",
        "# len(mobilnetv2_model.layers)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BRg3ml3EhlS"
      },
      "source": [
        "### Imagenet\n",
        "* Collection of labelled images from many categories\n",
        "* http://image-net.org/\n",
        "\n",
        "\n",
        "<table class=\"table-stats\" style=\"width: 500px\">\n",
        "<tbody><tr>\n",
        "<td width=\"25%\"><b>High level category</b></td>\n",
        "<td width=\"20%\"><b># synset (subcategories)</b></td>\n",
        "<td width=\"30%\"><b>Avg # images per synset</b></td>\n",
        "<td width=\"25%\"><b>Total # images</b></td>\n",
        "</tr>\n",
        "\n",
        "<tr><td>amphibian</td><td>94</td><td>591</td><td>56K</td></tr>\n",
        "\n",
        "<tr><td>animal</td><td>3822</td><td>732</td><td>2799K</td></tr>\n",
        "\n",
        "<tr><td>appliance</td><td>51</td><td>1164</td><td>59K</td></tr>\n",
        "\n",
        "<tr><td>bird</td><td>856</td><td>949</td><td>812K</td></tr>\n",
        "\n",
        "<tr><td>covering</td><td>946</td><td>819</td><td>774K</td></tr>\n",
        "\n",
        "<tr><td>device</td><td>2385</td><td>675</td><td>1610K</td></tr>\n",
        "\n",
        "<tr><td>fabric</td><td>262</td><td>690</td><td>181K</td></tr>\n",
        "\n",
        "<tr><td>fish</td><td>566</td><td>494</td><td>280K</td></tr>\n",
        "\n",
        "<tr><td>flower</td><td>462</td><td>735</td><td>339K</td></tr>\n",
        "\n",
        "<tr><td>food</td><td>1495</td><td>670</td><td>1001K</td></tr>\n",
        "\n",
        "<tr><td>fruit</td><td>309</td><td>607</td><td>188K</td></tr>\n",
        "\n",
        "<tr><td>fungus</td><td>303</td><td>453</td><td>137K</td></tr>\n",
        "\n",
        "<tr><td>furniture</td><td>187</td><td>1043</td><td>195K</td></tr>\n",
        "\n",
        "<tr><td>geological formation</td><td>151</td><td>838</td><td>127K</td></tr>\n",
        "\n",
        "<tr><td>invertebrate</td><td>728</td><td>573</td><td>417K</td></tr>\n",
        "\n",
        "<tr><td>mammal</td><td>1138</td><td>821</td><td>934K</td></tr>\n",
        "\n",
        "<tr><td>musical instrument</td><td>157</td><td>891</td><td>140K</td></tr>\n",
        "\n",
        "\n",
        "<tr><td>plant</td><td>1666</td><td>600</td><td>999K</td></tr>\n",
        "\n",
        "<tr><td>reptile</td><td>268</td><td>707</td><td>190K</td></tr>\n",
        "\n",
        "<tr><td>sport</td><td>166</td><td>1207</td><td>200K</td></tr>\n",
        "\n",
        "<tr><td>structure</td><td>1239</td><td>763</td><td>946K</td></tr>\n",
        "\n",
        "<tr><td>tool</td><td>316</td><td>551</td><td>174K</td></tr>\n",
        "\n",
        "<tr><td>tree</td><td>993</td><td>568</td><td>564K</td></tr>\n",
        "\n",
        "<tr><td>utensil</td><td>86</td><td>912</td><td>78K</td></tr>\n",
        "\n",
        "<tr><td>vegetable</td><td>176</td><td>764</td><td>135K</td></tr>\n",
        "\n",
        "<tr><td>vehicle</td><td>481</td><td>778</td><td>374K</td></tr>\n",
        "\n",
        "<tr><td>person</td><td>2035</td><td>468</td><td>952K</td></tr>\n",
        "\n",
        "</tbody></table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpvPzuUk-qhr"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def predict(model, img_path):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "\n",
        "    preds = model.predict(x)\n",
        "    # decode the results into a list of tuples (class, description, probability)\n",
        "    # (one such list for each sample in the batch)\n",
        "    print('Predicted:', decode_predictions(preds, top=3)[0])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-GkRqd7DPQJ"
      },
      "source": [
        "### Let's try it out on a few images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfwR9nMVCcS8",
        "outputId": "224adb5b-aa6e-4252-a6fd-e0a325610bf4"
      },
      "source": [
        "!curl -O https://upload.wikimedia.org/wikipedia/commons/thumb/d/de/Beagle_Upsy.jpg/440px-Beagle_Upsy.jpg"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 44891  100 44891    0     0   178k      0 --:--:-- --:--:-- --:--:--  178k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_03CM6Q4CsRc"
      },
      "source": [
        "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/d/de/Beagle_Upsy.jpg/440px-Beagle_Upsy.jpg'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ey2ZB23Dx6c",
        "outputId": "07a4867d-7250-4d84-d253-366ef2cfcf74"
      },
      "source": [
        "predict(model = mobilnetv2_model, img_path = '440px-Beagle_Upsy.jpg')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "40960/35363 [==================================] - 0s 0us/step\n",
            "49152/35363 [=========================================] - 0s 0us/step\n",
            "Predicted: [('n02088364', 'beagle', 0.40957186), ('n02101388', 'Brittany_spaniel', 0.14605413), ('n02089867', 'Walker_hound', 0.12106488)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhjjo44ICrgU",
        "outputId": "3f1b337a-0b34-4b5f-94e1-bf2da53e9d46"
      },
      "source": [
        "!curl -O https://djcordhose.github.io/ml-workshop/img/cat-bonkers.png"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  843k  100  843k    0     0  4154k      0 --:--:-- --:--:-- --:--:-- 4154k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHGt3752DAh0"
      },
      "source": [
        "<img src='https://djcordhose.github.io/ml-workshop/img/cat-bonkers.png'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQNqOpdgDiBi",
        "outputId": "05b0fa56-c2ad-4016-e77d-f3c784868d02"
      },
      "source": [
        "predict(model = mobilnetv2_model, img_path = 'cat-bonkers.png')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: [('n02124075', 'Egyptian_cat', 0.43944395), ('n02123045', 'tabby', 0.4016349), ('n02123159', 'tiger_cat', 0.03556939)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-q5OHiDDa86"
      },
      "source": [
        "# Exercise: Try this out on two of your images\n",
        "\n",
        "* If they are available on the internet, download them using CURL like the others\n",
        "* If they are local, upload them using the files dialog on the left sidebar\n",
        "\n",
        "How good are the results?\n",
        "* How sure is the network about its prediction?\n",
        "* Is it working well?\n",
        "* Why do you think it is working well or not so well?\n",
        "* How does this relate to the imagenet database?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kRWqxkDDwHn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}